{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "SEMMA â€” Shopping Behavior"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# SEMMA â€” Shopping Behavior\n_Last updated: 2025-11-01 17:42_"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n# Kaggle API setup (Colab-safe)\n\n1. Get your API key from Kaggle: Account â†’ **Create New API Token** â†’ downloads `kaggle.json`.\n2. In **Colab**: upload `kaggle.json` when prompted in the first cell below.\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": "\n#@title ðŸ”‘ Kaggle setup & dataset download\n# This cell works in Colab. If running locally, ensure kaggle is installed and KAGGLE_CONFIG_DIR is set.\nimport os, json, pathlib, zipfile, subprocess, sys\nfrom google.colab import files\n\nprint(\"Upload your kaggle.json (Kaggle â†’ Account â†’ Create New API Token).\")\nuploaded = files.upload()\nassert 'kaggle.json' in uploaded, \"Please upload kaggle.json\"\nos.makedirs('/root/.kaggle', exist_ok=True)\nwith open('/root/.kaggle/kaggle.json', 'wb') as f:\n    f.write(uploaded['kaggle.json'])\nos.chmod('/root/.kaggle/kaggle.json', 0o600)\n\n!pip -q install kaggle\n!kaggle datasets download -d ahmadrazakashif/shopping-behavior-dataset -p data --force\nos.makedirs(\"data\", exist_ok=True)\n# Unzip all archives\nfor z in os.listdir('data'):\n    if z.endswith('.zip'):\n        import zipfile\n        with zipfile.ZipFile(os.path.join('data', z)) as zz:\n            zz.extractall('data')\nprint(\"âœ… Dataset downloaded to ./data\")\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Sample\nDesign a sampling plan and document representativeness."
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": "# TODO: Implement stratified sample if classification target exists.",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Explore\nPerform thorough EDA connected to business questions."
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": "\nimport pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\nimport glob\nfiles = glob.glob('data/*.*'); print(files)\npath = [f for f in files if f.endswith(('.csv','.tsv','.xlsx','.parquet'))][0]\ndf = pd.read_csv(path) if path.endswith('.csv') else pd.read_excel(path) if path.endswith('.xlsx') else pd.read_parquet(path)\ndisplay(df.head()); display(df.describe(include='all'))\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Modify\nClean, engineer features, and prepare datasets."
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": "\n# TODO: implement preprocessing/feature engineering pipeline as needed\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Model\nTrain baseline and improved models with cross-validation."
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": "\n# TODO: train models and log metrics\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Assess\nEvaluate on holdout, do error analysis, and business interpretation."
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": "# TODO: error analysis and business recommendations",
      "outputs": [],
      "execution_count": null
    }
  ]
}